import streamlit as st
import google.generativeai as genai
import PyPDF2
import os
import pandas as pd
import io
import json
import docx  # è™•ç† .docx
from openpyxl import load_workbook

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="Meta å»£å‘Šå—çœ¾æˆ°ç•¥é¡§å• (Multi-Format)",
    page_icon="ğŸ“‚",
    layout="wide"
)

# --- å´é‚Šæ¬„ï¼šè¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±è¨­å®š")
    
    api_key = st.text_input("Gemini API Key", type="password", help="è«‹è¼¸å…¥ Google AI Studio API Key")
    
    st.markdown("### ğŸ¤– æ¨¡å‹ç‰ˆæœ¬")
    st.info("å·²é–å®šä½¿ç”¨ï¼š**gemini-2.5-pro**")
    model_version = "gemini-2.5-pro"

    st.markdown("---")
    st.info("ğŸ’¡ ç³»çµ±æ¨¡å¼ï¼šæœ¬åœ°è®€å–\n\nè‡ªå‹•è®€å– `meta_ads_targeting_database.md`ã€‚")

# --- æ ¸å¿ƒé‚è¼¯å‡½å¼ï¼šå¤šæ ¼å¼æå– ---

def extract_text_from_files(files):
    """æ ¹æ“šå‰¯æª”åè‡ªå‹•é¸æ“‡è§£ææ–¹å¼ä¸¦åˆä½µæ–‡å­—"""
    combined_text = ""
    for file in files:
        try:
            file_extension = file.name.split('.')[-1].lower()
            combined_text += f"\n--- æª”æ¡ˆå…§å®¹: {file.name} ---\n"
            
            # 1. PDF è™•ç†
            if file_extension == 'pdf':
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text = page.extract_text()
                    if text: combined_text += text + "\n"
            
            # 2. Word è™•ç† (.docx)
            elif file_extension == 'docx':
                doc = docx.Document(file)
                for para in doc.paragraphs:
                    combined_text += para.text + "\n"
            
            # 3. Excel è™•ç† (.xlsx, .xls)
            elif file_extension in ['xlsx', 'xls']:
                df = pd.read_excel(file)
                # å°‡ Excel è½‰æ›ç‚º CSV æ ¼å¼å­—ä¸²ï¼Œä¿ç•™çµæ§‹æ„Ÿä»¥ä¾¿ AI ç†è§£
                combined_text += df.to_csv(index=False) + "\n"
            
            # 4. JSON è™•ç†
            elif file_extension == 'json':
                json_data = json.load(file)
                combined_text += json.dumps(json_data, indent=2, ensure_ascii=False) + "\n"
            
            # 5. TXT è™•ç†
            elif file_extension == 'txt':
                stringio = io.StringIO(file.getvalue().decode("utf-8"))
                combined_text += stringio.read() + "\n"

        except Exception as e:
            st.error(f"è®€å–æª”æ¡ˆ {file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
    return combined_text

# --- æ ¸å¿ƒé‚è¼¯ï¼šGemini API ---

def get_gemini_response(api_key, model_name, db_context, user_input, user_files_content):
    """å‘¼å« Gemini API é€²è¡Œ RAG åˆ†æ"""
    genai.configure(api_key=api_key)
    
    generation_config = {
        "temperature": 0.2, 
        "top_p": 0.95,
        "max_output_tokens": 8192,
    }

    model = genai.GenerativeModel(
        model_name=model_name,
        generation_config=generation_config,
    )

    prompt = f"""
    è§’è‰²è¨­å®šï¼šä½ æ˜¯ä¸€ä½ç²¾é€š Meta å»£å‘Šç³»çµ±çš„è³‡æ·±æŠ•æ‰‹èˆ‡æ•¸æ“šç­–ç•¥å¸«ã€‚
    ä»»å‹™ç›®æ¨™ï¼šè«‹æ ¹æ“šæä¾›çš„ã€Œç”¢å“èˆ‡ç­–ç•¥è³‡è¨Šã€ï¼Œå¾ã€Œæ¨™æº–å—çœ¾è³‡æ–™åº«ã€ä¸­ç¯©é¸å‡ºæœ€é©åˆçš„ 10-20 çµ„å»£å‘Šå—çœ¾èˆˆè¶£æ¨™ç±¤ã€‚

    ğŸ“š æ¨™æº–å—çœ¾è³‡æ–™åº«ï¼š
    {db_context}

    ğŸ“ è£œå……æ–‡ä»¶èˆ‡è¼¸å…¥å…§å®¹ï¼š
    {user_input}
    {user_files_content}

    è¼¸å‡ºè¦æ±‚ï¼š
    1. æä¾› 20 çµ„å—çœ¾æ¨™ç±¤ã€‚
    2. åˆ†é¡æ˜ç¢ºï¼ˆäººå£/èˆˆè¶£/è¡Œç‚ºï¼‰ã€‚
    3. æ¨™è¨˜ã€âœ… è³‡æ–™åº«é©—è­‰ã€‘æˆ–ã€âš ï¸ æ½›åœ¨å—çœ¾ã€‘ã€‚
    4. è¼¸å‡º Markdown è¡¨æ ¼ï¼Œæ¬„ä½ï¼š| å„ªå…ˆåº | é¡åˆ¥ | å—çœ¾æ¨™ç±¤ (Tag) | ä¾†æºé©—è­‰ | æˆ°ç•¥é‚è¼¯èˆ‡æ‡‰ç”¨å ´æ™¯ |
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"API å‘¼å«éŒ¯èª¤: {str(e)}"

# --- è¼”åŠ©å‡½å¼ï¼šMarkdown è¡¨æ ¼è½‰ DF ---
def parse_markdown_table_to_df(markdown_text):
    try:
        lines = markdown_text.split('\n')
        table_lines = [line.strip() for line in lines if line.strip().startswith('|') and line.strip().endswith('|')]
        if len(table_lines) < 3: return None
        
        headers = [h.strip() for h in table_lines[0].strip('|').split('|')]
        data = []
        for line in table_lines[2:]:
            if '---' in line: continue
            values = [v.strip() for v in line.strip('|').split('|')]
            if len(values) == len(headers): data.append(values)
            elif len(values) > len(headers): data.append(values[:len(headers)])
            else: data.append(values + [''] * (len(headers) - len(values)))
        
        return pd.DataFrame(data, columns=headers) if data else None
    except:
        return None

def convert_df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='å—çœ¾æ¨™ç±¤å»ºè­°')
    return output.getvalue()

# --- ä¸»ç•«é¢ UI ---
st.title("ğŸ“‚ Meta å»£å‘Šå—çœ¾æˆ°ç•¥é¡§å• (å…¨æ ¼å¼æ”¯æ´)")

# è®€å–è³‡æ–™åº«
def get_local_database(filename="meta_ads_targeting_database.md"):
    if not os.path.exists(filename): return None, f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{filename}"
    with open(filename, "r", encoding="utf-8") as f: return f.read(), None

db_content, error_msg = get_local_database()

if error_msg:
    st.error(error_msg)
else:
    st.success(f"âœ… å·²è¼‰å…¥å—çœ¾è³‡æ–™åº«")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("1. è¼¸å…¥ç”¢å“è³‡è¨Š")
        user_strategy_text = st.text_area("ç›´æ¥æè¿°", height=200, placeholder="æè¿°æ‚¨çš„ç”¢å“...")

    with col2:
        st.subheader("2. ä¸Šå‚³ç­–ç•¥æ–‡ä»¶")
        uploaded_files = st.file_uploader(
            "æ”¯æ´ PDF, DOCX, XLSX, JSON, TXT", 
            type=['pdf', 'docx', 'xlsx', 'xls', 'json', 'txt'], 
            accept_multiple_files=True
        )

    if st.button("ğŸš€ å•Ÿå‹• AI æˆ°ç•¥åˆ†æ", type="primary"):
        if not api_key: st.stop()
        
        with st.spinner("ğŸ§  æ­£åœ¨è·¨æ ¼å¼æå–æ•¸æ“šä¸¦åˆ†æä¸­..."):
            # èª¿ç”¨æ–°çš„å¤šæ ¼å¼æå–å‡½å¼
            user_files_content = extract_text_from_files(uploaded_files) if uploaded_files else ""
            
            result = get_gemini_response(api_key, model_version, db_content, user_strategy_text, user_files_content)
            
            st.markdown("### ğŸ“Š AI æˆ°ç•¥åˆ†æå ±å‘Š")
            st.markdown(result)
            
            df = parse_markdown_table_to_df(result)
            if df is not None:
                excel_data = convert_df_to_excel(df)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel æ¸…å–®", data=excel_data, file_name='meta_audience_suggestions.xlsx', type="primary")
